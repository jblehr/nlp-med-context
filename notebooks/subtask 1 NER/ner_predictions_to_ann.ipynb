{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ner_predictions_to_ann.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"274e85d03f984f03b0209e234b6becb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b39d61115a440a0b9d837c911836b1e","IPY_MODEL_60539672821e47de8a5310e331e3cef2","IPY_MODEL_f9af4d1e17f34f9c84fc533a1978e8a5"],"layout":"IPY_MODEL_ac95bbd2f335459ca8712ab02f895a9d"}},"6b39d61115a440a0b9d837c911836b1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55ee33854964238a05d65001a70b201","placeholder":"​","style":"IPY_MODEL_4d1b691f3bf0459980d0fd5e6097f5b8","value":"100%"}},"60539672821e47de8a5310e331e3cef2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd8f9e1a6b6d4ba3b19ae6ebb3879027","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc987d9a0a484cafb5112981a212c6b8","value":3}},"f9af4d1e17f34f9c84fc533a1978e8a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d109e10141ea42cbb582250067aac2bc","placeholder":"​","style":"IPY_MODEL_5232705c4acf49a797b20c58869f2ba5","value":" 3/3 [00:00&lt;00:00, 52.44it/s]"}},"ac95bbd2f335459ca8712ab02f895a9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e55ee33854964238a05d65001a70b201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d1b691f3bf0459980d0fd5e6097f5b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd8f9e1a6b6d4ba3b19ae6ebb3879027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc987d9a0a484cafb5112981a212c6b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d109e10141ea42cbb582250067aac2bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5232705c4acf49a797b20c58869f2ba5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yCJ2VuLohG2o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647023844409,"user_tz":360,"elapsed":13539,"user":{"displayName":"Jacob Lehr","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15083895800350701205"}},"outputId":"821ede7d-3f55-4613-d52f-392404a773f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/NLP Project\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd '/content/drive/Shareddrives/NLP Project'"]},{"cell_type":"code","source":["import json\n","import os\n","from eval_script import ClinicalConcept"],"metadata":{"id":"ZJHVTdZdxk3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install libraries to make predictions\n","!pip install accelerate\n","!pip install seqeval\n","!pip install datasets \n","!pip install torch\n","!pip install git+https://github.com/huggingface/transformers"],"metadata":{"id":"XcWoGTegqLYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd '/content/drive/Shareddrives/NLP Project/notebooks/subtask 1 NER'\n","import ner_model\n","%cd '/content/drive/Shareddrives/NLP Project'"],"metadata":{"id":"iCnwko-LqxSC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647023920187,"user_tz":360,"elapsed":10894,"user":{"displayName":"Jacob Lehr","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15083895800350701205"}},"outputId":"5bcd5956-a194-42f6-fec1-7acbcb6c79cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/NLP Project/notebooks/subtask 1 NER\n","/content/drive/Shareddrives/NLP Project\n"]}]},{"cell_type":"code","source":["def generate_predictions(model_path, input_path, predict_path):\n","  # Note: train and valid file locations irrelevant;they are just needed for model to run\n","    arg_string = f'--model_name_or_path {model_path} \\\n","                  --do_predict \\\n","                  --test_file {input_path} \\\n","                  --train_file data/split_data/input/ner_input/ner_input_train.json \\\n","                  --validation_file data/split_data/input/ner_input/ner_input_dev.json \\\n","                  --output_dir {predict_path} \\\n","                  --overwrite_output_dir'\n","\n","    ner_model.main(arg_string)"],"metadata":{"id":"ETDyo3XkrbqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pre_process_results(predict_path, input_path):\n","    '''\n","    predict_path: (str) filepath of predicted labels (in txt file)\n","    input_path: (str) filepath of input data (in json form)\n","\n","    return:\n","        pred_lines: (list) of strings of len = no. sentences\n","        json_lines: (list) of json-formatted objects, len = no. sentences\n","    '''\n","    # predictions\n","    text = open(f'{predict_path}/predictions.txt', \"r\")\n","    pred_lines = [line for line in text]\n","    # input data\n","    json_file = open(input_path,'r')\n","    json_lines = [line for line in json_file]\n","    assert len(pred_lines)  == len(json_lines)\n","    return pred_lines, json_lines"],"metadata":{"id":"o9PzIB6nhY0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_sentences(pred_lines, json_lines):\n","    '''\n","    pred_lines: (list) of strings of len = no. sentences\n","    json_lines: (list) of json-formatted objects, len = no. sentences\n","\n","    return:\n","        doc_dic: (dict) of key = doc id (eg \"137-04\") and values = list of \n","                  medication mentions (ClinicalConcept) objects\n","    '''\n","    doc_dic = {}\n","    \n","    for sent_idx, pred_line in enumerate(pred_lines):\n","        json_sentence = json.loads(json_lines[sent_idx])\n","        doc_id = json_sentence['note_id']\n","        med_list = doc_dic.get(doc_id, [])\n","\n","        # Process one sentence by iterating over all labels\n","        for tok_idx, pred_label in enumerate(pred_line.split()):\n","            if pred_label != \"O\":\n","                tok_start, tok_end = json_sentence['token_spans'][tok_idx]\n","            \n","                if pred_label == \"B-MED\":\n","                    med_number = len(med_list) + 1\n","                    med_mention = ClinicalConcept(tid = f\"T{med_number}\",\n","                                                  start=tok_start,\n","                                                  end=tok_end,\n","                                                  text=json_sentence['tokens'][tok_idx],\n","                                                  ttype=\"Drug\")\n","                    med_list.append(med_mention)\n","\n","                elif pred_label == \"I-MED\":\n","                    # modify prev med mention to add on the I-MED\n","                    med_list[-1].end = tok_end\n","                    med_list[-1].text = med_list[-1].text + \" \" + json_sentence['tokens'][tok_idx]\n","        \n","        # update list for doc with changes\n","        doc_dic[doc_id] = med_list\n","    return doc_dic"],"metadata":{"id":"hr4bCJpeyvbQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def write_to_ann(doc_dic, ann_path):\n","    # Write results to ann files\n","    for ann_file, mention_list in doc_dic.items():\n","        file_name = f'{ann_path}/{ann_file}.ann'\n","        if os.path.exists(file_name):\n","            os.remove(file_name)\n","        with open(file_name, 'w') as ann:\n","            for mention in mention_list:\n","                # Note: format between different elements is very specific\n","                mention_str = f'{mention.rid}\\tUndetermined {mention.start} {mention.end}\\t{mention.text}\\n'\n","                ann.writelines(mention_str)\n","                event_str = f'''{mention.rid.replace(\"T\",\"E\")}\\tUndetermined:{mention.rid}\\n'''\n","                ann.writelines(event_str)\n","\n"],"metadata":{"id":"5jLP3tXIY-R9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main program execution\n","def go(model_path, predict_path, input_path, ann_path):\n","    '''\n","    model_path: (str) filepath of NER model\n","    predict_path: (str) filepath of predicted labels (in txt file)\n","    input_path: (str) filepath of input data (in json form)\n","    ann_path: (str) filepath to store new ann files\n","    '''\n","    generate_predictions(model_path, input_path, predict_path)\n","    pred_lines, json_lines = pre_process_results(predict_path, input_path)\n","    doc_dic = process_sentences(pred_lines, json_lines)\n","    write_to_ann(doc_dic, ann_path)\n","\n","# filepaths\n","model_path = 'data/models/NER'\n","predict_path = 'data/models/NER_predict'\n","input_path = 'data/split_data/input/ner_input/ner_input_test.json'\n","ann_path = 'data/split_data/output/ner_predicted_annotations/'\n","\n","go(model_path, predict_path, input_path, ann_path)"],"metadata":{"id":"x_emBNThhLq6","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["274e85d03f984f03b0209e234b6becb2","6b39d61115a440a0b9d837c911836b1e","60539672821e47de8a5310e331e3cef2","f9af4d1e17f34f9c84fc533a1978e8a5","ac95bbd2f335459ca8712ab02f895a9d","e55ee33854964238a05d65001a70b201","4d1b691f3bf0459980d0fd5e6097f5b8","cd8f9e1a6b6d4ba3b19ae6ebb3879027","bc987d9a0a484cafb5112981a212c6b8","d109e10141ea42cbb582250067aac2bc","5232705c4acf49a797b20c58869f2ba5"]},"executionInfo":{"status":"ok","timestamp":1647024085740,"user_tz":360,"elapsed":29650,"user":{"displayName":"Jacob Lehr","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15083895800350701205"}},"outputId":"4a74d585-adf3-4008-a9d8-e8b9bef664ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO|training_args.py:1014] 2022-03-11 18:40:54,511 >> PyTorch: setting up devices\n","[INFO|training_args.py:877] 2022-03-11 18:40:54,514 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["03/11/2022 18:40:54 - WARNING - ner_model - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","03/11/2022 18:40:54 - INFO - ner_model - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=False,\n","do_predict=True,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=data/models/NER_predict/runs/Mar11_18-40-54_1021338ce6ac,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=data/models/NER_predict,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=data/models/NER_predict,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","03/11/2022 18:40:54 - WARNING - datasets.builder - Using custom data configuration default-c20d063c61899a88\n","03/11/2022 18:40:54 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","03/11/2022 18:40:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-c20d063c61899a88/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\n","03/11/2022 18:40:54 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-c20d063c61899a88/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n","03/11/2022 18:40:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-c20d063c61899a88/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"274e85d03f984f03b0209e234b6becb2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:647] 2022-03-11 18:40:55,082 >> loading configuration file data/models/NER/config.json\n","[INFO|configuration_utils.py:685] 2022-03-11 18:40:55,085 >> Model config BertConfig {\n","  \"_name_or_path\": \"data/models/NER\",\n","  \"architectures\": [\n","    \"BertForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"finetuning_task\": \"ner\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"B-MED\",\n","    \"1\": \"I-MED\",\n","    \"2\": \"O\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-MED\": 0,\n","    \"I-MED\": 1,\n","    \"O\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.18.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|tokenization_utils_base.py:1703] 2022-03-11 18:40:55,105 >> Didn't find file data/models/NER/added_tokens.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1784] 2022-03-11 18:40:55,112 >> loading file data/models/NER/vocab.txt\n","[INFO|tokenization_utils_base.py:1784] 2022-03-11 18:40:55,113 >> loading file data/models/NER/tokenizer.json\n","[INFO|tokenization_utils_base.py:1784] 2022-03-11 18:40:55,117 >> loading file None\n","[INFO|tokenization_utils_base.py:1784] 2022-03-11 18:40:55,120 >> loading file data/models/NER/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:1784] 2022-03-11 18:40:55,125 >> loading file data/models/NER/tokenizer_config.json\n","[INFO|modeling_utils.py:1429] 2022-03-11 18:40:55,163 >> loading weights file data/models/NER/pytorch_model.bin\n","[INFO|modeling_utils.py:1702] 2022-03-11 18:40:57,004 >> All model checkpoint weights were used when initializing BertForTokenClassification.\n","\n","[INFO|modeling_utils.py:1711] 2022-03-11 18:40:57,007 >> All the weights of BertForTokenClassification were initialized from the model checkpoint at data/models/NER.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["03/11/2022 18:40:57 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-c20d063c61899a88/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-6770ea8db1dbea12.arrow\n","03/11/2022 18:40:57 - INFO - ner_model - *** Predict ***\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:571] 2022-03-11 18:40:57,395 >> The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, token_spans, tokens, note_id. If ner_tags, token_spans, tokens, note_id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2403] 2022-03-11 18:40:57,407 >> ***** Running Prediction *****\n","[INFO|trainer.py:2405] 2022-03-11 18:40:57,412 >>   Num examples = 1984\n","[INFO|trainer.py:2408] 2022-03-11 18:40:57,414 >>   Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 00:24]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["03/11/2022 18:41:23 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:460] 2022-03-11 18:41:23,596 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}}\n"]},{"output_type":"stream","name":"stdout","text":["***** predict metrics *****\n","  predict_accuracy           =     0.9982\n","  predict_f1                 =     0.9451\n","  predict_loss               =     0.0109\n","  predict_precision          =     0.9385\n","  predict_recall             =     0.9518\n","  predict_runtime            = 0:00:25.74\n","  predict_samples_per_second =     77.051\n","  predict_steps_per_second   =      9.631\n"]}]},{"cell_type":"code","source":["# try evaluation script on test data\n","!python3 notebooks/eval_script.py data/split_data/test/ data/split_data/ner_predicted_annotations/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yltzqp6Y_46","executionInfo":{"status":"ok","timestamp":1647024128653,"user_tz":360,"elapsed":10898,"user":{"displayName":"Jacob Lehr","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15083895800350701205"}},"outputId":"4dcba5b3-40c3-4dad-c761-797bc0063386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","******************** Evaluation n2c2 2022 Track 1 ********************\n","************* Contextualized Medication Event Extraction *************\n","\n","*********************** Medication Extraction ************************\n","                      ------- strict -------    ------ lenient -------\n","                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n","                Drug  0.9519  0.9439  0.9479    0.9760  0.9677  0.9718\n","\n","\n","************************ Event Classification ************************\n","                      ------- strict -------    ------ lenient -------\n","                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n","         Disposition  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","       Nodisposition  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","        Undetermined  0.0849  0.9677  0.1560    0.0849  0.9677  0.1560\n","                      ------------------------------------------------\n","     Overall (micro)  0.0849  0.0842  0.0845    0.0849  0.0842  0.0845\n","     Overall (macro)  0.0283  0.3226  0.0520    0.0283  0.3226  0.0520\n","\n","\n","*********************** Context Classification ***********************\n","                      ------- strict -------    ------ lenient -------\n","                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n","              Action  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","         Temporality  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","           Certainty  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","               Actor  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","            Negation  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","                      ------------------------------------------------\n","     Overall (micro)  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","     Overall (macro)  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","\n","\n","                      ------- strict -------    ------ lenient -------\n","                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n","            Combined  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000\n","\n","\n","                                   40 files evaluated               \n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"uVFfzi1k6V7v"},"execution_count":null,"outputs":[]}]}